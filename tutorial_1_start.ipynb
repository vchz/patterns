{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turing patterns\n",
    "\n",
    "As an example of a system that exhibits Turing patterns, let us consider the activator–substrate depletion model (ASDM). This model involves two species: an activator and a substrate. The activator promotes its own production (autocatalysis) while consuming the substrate in the process, and it also undergoes standard degradation. The substrate, on the other hand, is produced at a constant rate only degrades as a result of its consumption by the activator.\n",
    "\n",
    "\n",
    "$$\\frac{\\partial a}{\\partial t} = d \\Delta a + a^2s - a, \\\\ \\frac{\\partial s}{\\partial t} = \\Delta s + \\mu (1-a^2s).$$\n",
    "\n",
    "There exists a unique steady-state $a^* = s^* = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Plotting the linear stability diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a linear stability analysis around this homoegenous steady-state. We look for solutions of the form:\n",
    "\n",
    "$$a = a^* + \\delta a = a^* + \\delta a_0 e^{-ikx + \\lambda t}\\\\ s = s^* + \\delta s = s^* + \\delta s_0 e^{-ikx + \\lambda t},$$\n",
    "\n",
    "with $\\delta a_0, \\delta s_0 \\ll 1$. After linearizing the equations, we find that $\\lambda$ is an eigenvalue of the linear stability matrix $A$:\n",
    "\n",
    "$$A = \\begin{pmatrix} 1 - dk^2 & 1 \\\\ -2 \\mu &- \\mu - k^2 \\end{pmatrix}.$$\n",
    "\n",
    "Because it's a 2D matrix, the eigenvalues can be written\n",
    "\n",
    "$$\\lambda = \\frac{1}{2} \\left( \\mathrm{tr} (A) \\pm \\sqrt{\\mathrm{tr}^2 (A) - 4 \\det (A)} \\right).$$\n",
    "\n",
    "To classify the behavior of the system we investigate the maximum growth rate attainable, $g^* = \\max\\limits_{k \\geq 0} \\Re(\\lambda)$ and the value at which it is attained $k^* = \\arg\\max\\limits_{k \\geq 0} \\Re(\\lambda).$\n",
    "\n",
    "If $g^* > 0$ and $k^* > 0$, the instability develop with finite wavelength: these are Turing patterns. If $g^* > 0$ and $k^* = 0$, the instability develops but remains homogeneous, there are no patterns. If $g^* < 0$, the steady-state solution is stable.\n",
    "\n",
    "1. We note that $\\mathrm{tr} (A) = 1 - \\mu - dk^2 - k^2$, such that if $\\mu < 1$ we are guaranteed that $g^* > 0$ because $\\mathrm{tr}(A) > 0$ for $k = 0$. Indeed, no matter the value of the discriminant at $k=0$, we know that at least $\\Re(\\lambda(k=0)) > 0$, which means that $g^* > 0$.\n",
    "\n",
    "2. We also have that if $\\mu > 3 - 2\\sqrt{2}$, $\\lambda(k = 0)$ has a non-zero imaginary part, such that an oscillating instability can develop. This instability can be in competition with a purely real instability with $k > 0$. In this case, because the instabilities have different types, if they can be in competition it will depend on the initial condition.\n",
    "\n",
    "3. Finally, when $\\mu < 3 - 2 \\sqrt{2}$, the discriminant is always positive, so there can't be oscillations in time. However, depending on the value of the parameters we can have $k^* = 0$ or $k^* > 0$.\n",
    "\n",
    "**<font color='red'>Using this insights, plot the linear stability diagram. You will first need to generate a function `get_real_lambda(k,d,mu)` which returns the real part of the the eigenvalue lambda for a value of $k$, of $d$ and of $\\mu$. You will then define the function `phase_diagram(d, mu)` which returns a specific flag (any integer works) if $k^* > 0$ and another flag if $k^* = 0$.</font>** You can also separate the different case $\\mu > 1$, $1 > \\mu > 3 - 2\\sqrt{2}$ and $\\mu < 3 -2\\sqrt{2}$ since they correspond to different type of instabilities. Doing so, you should have 4 different regions: Turing pattern, homogeneous instability, stable, oscillatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_lambda(k, d, mu):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the real part of the dominant eigenvalue λ(k) for the linearized ASDM model.\n",
    "\n",
    "    This function evaluates the growth rate of Fourier modes of wavenumber k\n",
    "    based on the Jacobian of the linearized dynamics and diffusion term.\n",
    "\n",
    "    Parameters:\n",
    "        k : np.ndarray\n",
    "            Array of wavenumbers.\n",
    "        d : float\n",
    "            Diffusion coefficient for the activator.\n",
    "        mu : float\n",
    "            Growth rate of the substrate.\n",
    "\n",
    "    Returns:\n",
    "        Rlam : np.ndarray\n",
    "            Array of the real part of the leading eigenvalue for each wavenumber.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO\n",
    "    \n",
    "    return Rlam\n",
    "\n",
    "def phase_diagram(d, mu):\n",
    "    \n",
    "    \"\"\"\n",
    "    Classifies the system behavior for given diffusion d and growth rate μ.\n",
    "    It returns an integer label corresponding to the six possible regimes:\n",
    "    Turing pattern, homogeneous instability, stable, oscillatory\n",
    "    \n",
    "    Inputs:\n",
    "        d : float\n",
    "            Diffusion coefficient of the activator.\n",
    "        mu : float\n",
    "            Growth rate of the substrate.\n",
    "    \n",
    "    Returns:\n",
    "        label : int\n",
    "            Integer identifier for the dynamical regime.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    k = np.linspace(0, 4, 200)\n",
    "    Rlam = get_real_lambda(k, d, mu)\n",
    "    \n",
    "    # TODO\n",
    "        \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = np.linspace(0.01, 2, 300)\n",
    "ds = np.linspace(0.01, 1, 300)\n",
    "\n",
    "\n",
    "d, mu = np.meshgrid(ds, mus)\n",
    "im = np.empty_like(d)\n",
    "for i in range(len(mus)):\n",
    "    for j in range(len(ds)):\n",
    "        im[i, j] = phase_diagram(ds[j], mus[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.pcolor(ds, mus, im)\n",
    "plt.xlabel('diffusion, d')\n",
    "plt.ylabel('growth, mu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparison with analytical predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With mathematica we can find the maximum of $\\Re(\\lambda)$ as a function of $k$, and then compute $g^*$. We have that there always exists an extremum at $k > 0$ for $3 - 2 \\sqrt{2} < \\mu < 2$ and $0 < d < 1$. This value and the value for the corresponding maximum read\n",
    "\n",
    "$$\n",
    "k^* = \\sqrt{\\frac{1 + \\mu - \\sqrt{2 \\mu/d}(d+1)}{d - 1}} \\\\\n",
    "g^* = \\frac{1 + d \\mu - 2 \\sqrt{2 d \\mu}}{1 - d}\n",
    "$$\n",
    "\n",
    "**<font color='red'>Using this value for $g^*$, you compare it to the $\\Re(\\lambda(k=0))$ to derive the boundaries of the different phases in for $3 - 2 \\sqrt{2} < \\mu < 2$ and $0 < d < 1$.</font>** **<font color='red'>For $\\mu < 3 - 2\\sqrt{2}$ the boundary between the Turing patterns and the homogeneous instability can be calculated by finding the value of the parameters for which the value of $k^*$ above reaches zero. Doing so, obtain the three boundaries analytically and superimpose them on the phase diagram in the cells below.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plotting the real part of $\\lambda$ in the different phases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>For one set of parameters for each region plot the real part of $\\lambda$ as a function of $k$. Use the following set of parameters, $(d, mu)$:</font>** $(0.05, 0.1), (0.4, 0.1), (0.05, 0.5), (0.4, 0.5), (0.05, 1.4), (0.4, 1.4)$. On each of these plot, overlay the analtyical prediction for $k^*$. Except for one of the phases where this prediction doesn't hold, it should correspond the value at which $\\Re(\\lambda)$ is maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kstar(d, mu):\n",
    "    \n",
    "    \"\"\"\n",
    "    Analytically computes the predicted most unstable wavenumber k*,\n",
    "    valid in the weakly nonlinear regime.\n",
    "\n",
    "    Inputs:\n",
    "        d : float\n",
    "            Diffusion coefficient of the activator.\n",
    "        mu : float\n",
    "            Growth rate of the substrate.\n",
    "\n",
    "    Returns:\n",
    "        k_star : float or None\n",
    "            Most unstable wavevector if it exists; None otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    return k_star\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(12,6),nrows = 2, ncols = 3)\n",
    "\n",
    "k = np.linspace(0, 4, 200)\n",
    "parameters = [(0.05, 0.1), (0.4, 0.1), (0.05, 0.5), (0.4, 0.5), (0.05, 1.4), (0.4, 1.4)] #[d,mu]\n",
    "\n",
    "for (d, mu), ax in zip(parameters, axes.flatten()):\n",
    "\n",
    "    ax.plot(k, get_real_lambda(k, d, mu), '-')\n",
    "    kstar = get_kstar(d, mu)\n",
    "    if kstar is not None:\n",
    "        ax.axvline(x = kstar, color='k', label=r'$k^*$')\n",
    "    ax.axhline(y = 0, linestyle = '--', color = 'r')\n",
    "    ax.set_xlabel(r'wave vector, k')\n",
    "    ax.set_ylabel(r'real part of $\\lambda$')\n",
    "    ax.legend(frameon=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 1D finite difference simulations of Turing patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will simulate via finite differences the ASDM model, first in 1D, and you will explore the Turing pattern regime with $d = 0.05, \\mu = 1.4$. The system can be rewritten in the following way:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial Y}{\\partial t} = F(Y), \\text{ with } Y = \\begin{pmatrix}a \\\\ s \\end{pmatrix}, \\text{ and } F(Y) = \\begin{pmatrix} d \\Delta a + a^2 s -a \\\\ \\Delta s + \\mu(1 - a^2 s) \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Finite differences are a way to approximate derivatives. For instancem, in 1D, for the activator $a$, on a grid with spacing $\\Delta x$ the derivative of a $\\partial_x a\n",
    "\n",
    "$$\n",
    "\\partial_x a(x,t) \\simeq \\frac{a(x + \\Delta x,t) - f(x,t)}{\\Delta x}\n",
    "$$\n",
    "\n",
    "Similarly, the second order derivative (laplacian in one dimension) can be written as:\n",
    "\n",
    "$$\n",
    "\\partial^2_x a = \\Delta a \\simeq \\frac{a(x + \\Delta x,t) + a(x - \\Delta x,t) - 2a(x,t)}{\\Delta x}\n",
    "$$\n",
    "\n",
    "And we are guaranteed that these approximations are exact in the limit $\\Delta x \\rightarrow 0$. The integration of the equations in time can be done by Euler time-stepping:\n",
    "\n",
    "$$\n",
    "Y(t+\\Delta t) = Y(t) + \\Delta t F(Y(t))\n",
    "$$\n",
    "\n",
    "**<font color='red'>You will simulate a system of length $L = 20$, with $N = 128$ points (hence with $\\Delta x = L/(N-1)$), time step $\\Delta t = 0.001$ and for a duration $T = 100$, and $d = 0.05, \\mu = 1.4$</font>** You will initialize the system as a small perturbation ($10^{-3}$) around the steady-state values $a^* = 1$, $s^* = 1$ of $a$ and $s$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian(X, dx):\n",
    "    \"\"\"\n",
    "    Computes the finite-difference Laplacian of a field with periodic boundary conditions.\n",
    "    \n",
    "    Inputs:\n",
    "        X : ndarray\n",
    "            Input array of shape (time, space)\n",
    "        dx : float\n",
    "            Grid spacing.\n",
    "    \n",
    "    Returns:\n",
    "        L : ndarray\n",
    "            Laplacian of X, same shape as input.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    return L\n",
    "\n",
    "\n",
    "def asdm_force(X, dx, args):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the ASDM force field for the current state X and parameters.\n",
    "\n",
    "    Inputs:\n",
    "        X : ndarray\n",
    "            Array of shape (time, 2, space) for [a, s], X[:,0,:] is field a(x,t) and X[:,1,:] is s(x,t)\n",
    "        dx : float\n",
    "            Grid spacing.\n",
    "        args : tuple\n",
    "            Model parameters (d, μ).\n",
    "    \n",
    "    Returns:\n",
    "        dX : ndarray\n",
    "            Time derivative (force) of X.\n",
    "    \"\"\"\n",
    "    dXdt = np.empty_like(X)\n",
    "    d, mu = args\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    return dXdt\n",
    "\n",
    "def simulate(X0, force_args, force_function=asdm_force, N=32, T=5000, dt=0.005, L=50,\n",
    "             num=70):\n",
    "    \"\"\"\n",
    "    Simulates the ASDM system over time using Euler time-stepping and returns the trajectory.\n",
    "\n",
    "    Inputs:\n",
    "        X0 : ndarray\n",
    "            Initial condition, shape (2, space), ie (2, N)\n",
    "        force_args : tuple\n",
    "            Parameters for the force function (e.g., (d, μ)).\n",
    "        force_function : callable\n",
    "            Function to compute the time derivative.\n",
    "        N : int\n",
    "            Grid size.\n",
    "        T : float\n",
    "            Total simulation time.\n",
    "        dt : float\n",
    "            Time step.\n",
    "        L : float\n",
    "            Length of the domain.\n",
    "        num : int\n",
    "            Store one frame every 'num' steps.\n",
    "\n",
    "    Returns:\n",
    "        trajectory : ndarray\n",
    "            Array of stored timepoints, shape (time, 2, N) or (time, 2, N, N).\n",
    "    \"\"\"\n",
    "    dx = L / (N - 1)\n",
    "    X = X0[None,:]\n",
    "    trajectory = []\n",
    "    n_iter = int(T/dt)\n",
    "\n",
    "    for i in tqdm(range(n_iter)):\n",
    "        force = force_function(X, dx, force_args)\n",
    "        X += dt * force\n",
    "\n",
    "        if i % num == 0:\n",
    "            trajectory.append(X[0,:].copy())\n",
    "\n",
    "    trajectory = np.array(trajectory)\n",
    "    return trajectory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=0.001\n",
    "L=20.0\n",
    "N=128\n",
    "T=80\n",
    "force_args=(0.05, 1.4)\n",
    "\n",
    "np.random.seed(42)\n",
    "a0 = np.ones(N) + 1e-6*np.random.normal(size = N)\n",
    "s0 = np.ones(N) + 1e-6*np.random.normal(size = N)\n",
    "\n",
    "X = simulate(np.array([a0, s0]), force_args, N=N, T=T, dt=dt, L=L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(X[-1,0,:], 'o-')\n",
    "plt.plot(X[-1,1,:], 'o-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Wavenumber selection, comparison between linear and non-linear theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Using the last time point of the simulation, compute the typical wavenumber $k = 2\\pi/\\lambda$ with the discrete fourier transform.</font>** Compare this to the prediction $k^*$ for the linear theory with the same parameters used for the simulation. With the set of parameters $(0.05, 1.4)$ the solution is weakly non-linear, and the wave number selected is not too far from the one predicted by the theory. As we decrease $d$ it gets more clearly non-linear. For $(d, \\mu) = (0.05, 1.4)$ the wave number selected by the instability clearly deviates more from the prediction of the linear theory than when the solution looks more sinusoidal. The problem of predicting the exact wavenumber selected is still an open question in the study of dynamical systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_kstar(X, dx):\n",
    "    \"\"\"\n",
    "    Estimates the dominant wavenumber of a spatial pattern.\n",
    "\n",
    "    Inputs:\n",
    "        X : ndarray\n",
    "            Input 1D spatial profile (e.g., last frame of activator concentration).\n",
    "        dx : grid spacing (assumed isotropic)\n",
    "\n",
    "    Returns:\n",
    "        k_star : float\n",
    "            Dominant wavenumber 2π/λ.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    return k_estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('selected mode from linear theory', get_kstar(0.1, 1.4))\n",
    "print('selected mode in practice (non-linear effects matter)', estimate_kstar(X[-1,0,:], L/(N-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 2D finite difference simulations of Turing patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Extend your finite difference simulation to a 2D setting.</font>** Use the same grid size in $x$ and $y$ direction. The approximation for the Laplacian can be extended easily from one dimension. In fact, you can simply write a laplacian function which works in any dimension:\n",
    "\n",
    "$$\n",
    "\\partial^2_x a + \\partial^2_y a = \\Delta a \\simeq \\frac{a(x + \\Delta x,y,t) + a(x - \\Delta x,y,t) + a(x,y +\\Delta t,t) + a(x,y - \\Delta y, t) - 4 a(x,y,t)}{\\Delta x^2}\n",
    "$$\n",
    "\n",
    "You will use for each dimension length $L=20$ and $N=128$ points, the time step is $\\Delta t = 0.001$ and total simulation time $T = 80$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=0.001\n",
    "L=20\n",
    "N=128\n",
    "T=80\n",
    "force_args=(0.05, 1.4)\n",
    "\n",
    "np.random.seed(0)\n",
    "a0 = np.ones((N,N)) + 1e-4*np.random.normal(size = (N,N))\n",
    "s0 = np.ones((N,N)) + 1e-4*np.random.normal(size = (N,N))\n",
    "\n",
    "X = simulate(np.array([a0, s0]), force_args, N=N, T=T, dt=dt, L=L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "im = plt.imshow(X[-1,0,:], cmap='plasma')\n",
    "plt.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summarizing the phase-diagram with simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will explore the different phases for this set of parameters $(d,\\mu)$: $(0.05, 0.1), (0.4, 0.1), (0.05, 0.5), (0.4, 0.5), (0.05, 1.4), (0.4, 1.4)$. Each of this parameter corresponds to one of the phases. **<font color='red'>For each of this parameter run a simulation, and store the last time point for the concentration fields as well as the mean value over the domain of substrate concentration as a function of time. Plot the mean value of the substrate concentration for eah of the parameters, as well as the substrate concentration field at the last time point.</font>** You should see patterns in the phases you expect patterns according to your prior analysis. With the mean value plot you should also be able to see which phases are stable and which are unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Drawing new Turing patterns by introducing saturation of the autocatalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can slightly modify the ASDM model to include the possibility of saturation of the autocatalysis of the activator species $a$. This is done by introducing a parameter $\\kappa > 0$ and a Hill function for the autocatalysis of the activator. The equations read:\n",
    "\n",
    "$$\\frac{\\partial a}{\\partial t} = d \\Delta a + \\frac{a^2s}{1 + \\kappa a^2} - a, \\\\ \\frac{\\partial s}{\\partial t} = \\Delta s + \\mu (1-\\frac{a^2s}{1 + \\kappa a^2}).$$\n",
    "\n",
    "**<font color='red'>Modify the force of the asdm model to account for this new effect, and run new simulations in 2D with parameters $\\kappa = 0.1, d = 0.05, \\mu = 1.4, N = 64, T = 80$.</font>** Plot the resulting 2D field. You should now see a different type of pattern with stripes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_asdm_full(X, dx, force_args):\n",
    "    \"\"\"\n",
    "    Computes the ASDM force with a saturating nonlinearity using a Hill function.\n",
    "\n",
    "    Inputs:\n",
    "        X : ndarray\n",
    "            Input state array (time, 2, space).\n",
    "        dx : float\n",
    "            Grid spacing.\n",
    "        force_args : tuple\n",
    "            Model parameters (d, μ, κ).\n",
    "\n",
    "    Returns:\n",
    "        dXdt : ndarray\n",
    "            Computed time derivative at each point.\n",
    "    \"\"\"\n",
    "    \n",
    "    dXdt = np.empty_like(X)\n",
    "    d, mu, K = force_args\n",
    "\n",
    "    # TODO\n",
    "    \n",
    "    return dXdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=0.001\n",
    "L=20.0\n",
    "N=64\n",
    "T=80\n",
    "force_args=(0.05, 1.4, 0.1)\n",
    "\n",
    "np.random.seed(42)\n",
    "a0 = np.ones((N,N)) + 1e-4*np.random.normal(size = (N,N))\n",
    "s0 = np.ones((N,N)) + 1e-4*np.random.normal(size = (N,N))\n",
    "\n",
    "X = simulate(np.array([a0, s0]), force_args, force_function=force_asdm_full, N=N, T=T, dt=dt, L=L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "im = plt.imshow(X[-1,0,:], cmap='plasma')\n",
    "plt.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrna",
   "language": "python",
   "name": "scrna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
