{"cells":[{"cell_type":"markdown","metadata":{"id":"b8bXu3b5z540"},"source":["# Force inference from stochastic trajectories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2HGprk4Lz542"},"outputs":[],"source":["import sys\n","data_path = './'\n","if 'google.colab' in sys.modules:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    data_path = '/content/drive/My Drive/biophysics_summer_school_2025/data_tutorial_3/'\n","    sys.path.append('/content/drive/My Drive/biophysics_summer_school_2025')\n","\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from utils import get_basis, greedy_basis_search, evaluate_basis, get_latex_model, get_model_from_labels, add_superfluous_functions"]},{"cell_type":"markdown","metadata":{"id":"pSjIZF7sz544"},"source":["## 1. Simulating the stochastic Lorenz system"]},{"cell_type":"markdown","metadata":{"id":"DAAMraJWz545"},"source":["We consider a stochastic trajectory $\\{\\mathbf{x}_t\\}$ sampled at constant time intervals $\\Delta t$. The dynamics are governed by the SDE:\n","\n","$$\n","\\frac{d\\mathbf{x}_t}{dt} = \\mathbf{F}(\\mathbf{x}_t) + \\sqrt{2\\mathbf{D}} \\, \\boldsymbol{\\xi}_t,\n","$$\n","\n","where $\\mathbf{F}(\\mathbf{x})$ is the unknown force field, $\\mathbf{D}$ is the (constant) diffusion matrix, and $\\boldsymbol{\\xi}_t$ is a Gaussian white noise. In this specific tutorial we consider the case $\\mathbf{x} = (x, y, z)$ with $\\mathbf{F}$ is the deterministic Lorenz drift. The deterministic Lorenz dynamics are:\n","\n","\\begin{aligned}\n","\\frac{dx}{dt} &= \\sigma (y - x), \\\\\n","\\frac{dy}{dt} &= x (\\rho - z) - y, \\\\\n","\\frac{dz}{dt} &= xy - \\beta z.\n","\\end{aligned}\n","\n","We can simulate using the Euler–Maruyama method, which approximates stochastic differential equations over small time steps:\n","\n","$$\n","\\mathbf{x}_{t+\\Delta t} = \\mathbf{x}_t + \\mathbf{F}(\\mathbf{x}_t) \\, \\Delta t + \\sqrt{2\\mathbf{D} \\, \\Delta t} \\cdot \\boldsymbol{\\eta}_t,\n","$$\n","\n","where $\\boldsymbol{\\eta}_t \\sim \\mathcal{N}(0, I)$. **<font color='red'>Simulate this system with $\\sigma = 10$, $\\rho = 28$, $\\beta = \\frac{7}{3}$, $D = 10$, $\\Delta t = 10^{-4}$, $T = 150$.</font>**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cRP6-Kbnz546"},"outputs":[],"source":["def lorenz_force(X, args):\n","    \"\"\"\n","    Compute the deterministic Lorenz drift vector field for input positions.\n","\n","    Parameters:\n","        X : ndarray of shape (time, 3)\n","            Points at which to evaluate the force.\n","        args : tuple of floats (sigma, rho, beta)\n","            Lorenz system parameters.\n","\n","    Returns:\n","        dXdt : ndarray of shape (time, 3)\n","            Time derivative at each position.\n","    \"\"\"\n","\n","    dXdt = np.empty_like(X)\n","    sigma, rho, beta = args\n","\n","    # TODO\n","\n","    return dXdt\n","\n","def simulate(X0, force_args, force_function=lorenz_force,\n","             dt=0.0002, T=20.0, D=100.0, num=10):\n","\n","    \"\"\"\n","    Simulate a stochastic trajectory using Euler-Maruyama integration.\n","\n","    Parameters:\n","        X0 : ndarray of shape (3,)\n","            Initial condition for the Lorenz system.\n","        force_args : tuple\n","            Parameters for the deterministic force.\n","        force_function : callable\n","            Function computing the drift force.\n","        dt : float\n","            Time step.\n","        T : float\n","            Total duration to record.\n","        D : float\n","            Scalar noise strength.\n","        num : int\n","            Store one frame every 'num' steps.\n","\n","    Returns:\n","        trajectory : ndarray of shape (time, 3), stochastic trajectory:\n","    \"\"\"\n","\n","    # TODO\n","\n","    return trajectory\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CWaShYN1z547"},"outputs":[],"source":["dt=0.0001\n","T=100.0\n","D=10\n","num=20\n","np.random.seed(2)\n","x0 = np.array([0.5, 0.5, 23])\n","force_args = (10.0, 28.0, 7.0/3.0)\n","\n","X = simulate(x0, force_args, dt=dt, T=T, D=D, num = num)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tk63pOOez548"},"outputs":[],"source":["x = X[:, 0]\n","y = X[:, 1]\n","z = X[:, 2]\n","t = np.arange(len(x)) * dt\n","\n","plt.figure(figsize=(8, 6))\n","scatter = plt.scatter(x, z, c=t, cmap='viridis', s=0.8)\n","plt.xlabel(\"x\")\n","plt.ylabel(\"z\")\n","plt.title(\"Lorenz Trajectory (x vs z)\")\n","cbar = plt.colorbar(scatter, label='Time')\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"QTI4aglWz549"},"source":["## 2. Estimating the diffusion coefficient"]},{"cell_type":"markdown","metadata":{"id":"ik0tZnkHz549"},"source":["In order to infer the force field, we first need to the diffusion matrix $\\hat{\\mathbf{D}} \\simeq \\mathbf{D}$. To do that, we can simply build a naive estimator using the Euler-Maryuma time stepping. When $\\Delta t \\rightarrow 0$ we have that:\n","\n","$$\n","\\hat{\\mathbf{D}} \\simeq \\frac{1}{2\\Delta t} \\langle \\Delta \\mathbf{x}_t \\Delta \\mathbf{x}_t^T \\rangle\n","$$\n","\n","**<font color='red'>Write the function to compute the mean diffusion and compare the diffusion matrix inferred to the true one, which is diagonal with $D = 10$.</font>**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sax9I1GCz54-"},"outputs":[],"source":["def compute_mean_diffusion(X, T):\n","    \"\"\"\n","    Estimate the diffusion matrix from a trajectory using the empirical second moment.\n","\n","    Parameters:\n","        X : ndarray of shape (Nt, d)\n","            Trajectory data.\n","        T : float\n","            Total time of the trajectory.\n","\n","    Returns:\n","        Dhat : ndarray of shape (d, d)\n","            Estimated diffusion matrix.\n","    \"\"\"\n","\n","    dt = T/X.shape[0]\n","\n","    # TODO\n","\n","    return Dhat\n"]},{"cell_type":"markdown","metadata":{"id":"577062Qaz54-"},"source":["## 3. Regressing the force field"]},{"cell_type":"markdown","metadata":{"id":"uU-14cgUz54-"},"source":["We now implement the force inference step of the PASTIS method in discrete time. To infer $\\mathbf{F}$ from data, we introduce a test force field $\\hat{\\mathbf{F}}(\\mathbf{x})$, assumed to lie in a linear span of vector basis functions $\\{\\mathbf{b}_i(\\mathbf{x})\\}$:\n","\n","$$\n","\\hat{\\mathbf{F}}(\\mathbf{x}) = \\sum_{i=1}^{n_B} \\hat{F}_i \\, \\mathbf{b}_i(\\mathbf{x}),\n","$$\n","\n","where the coefficients $\\hat{F}_i$ are to be inferred from the data. A notation of importance is the average over time, which simply implements Riemann integral, with $T$ is the total duration of the trajectory and $\\Delta t$ the time step.\n","\n","$$\n","\\langle \\cdot \\rangle = \\frac{1}{T} \\sum_t \\cdot \\Delta t\n","$$\n","The log-likelihood of the trajectory under the test force field is approximated in discrete time by:\n","\n","$$\n","\\mathcal{L}(\\hat{\\mathbf{F}}) = -\\frac{T}{4} \\langle  \\left( \\frac{\\Delta \\mathbf{x}_t}{\\Delta t} - \\hat{\\mathbf{F}}(\\mathbf{x}_t) \\right)^T \\hat{\\mathbf{D}}^{-1} \\left( \\frac{\\Delta \\mathbf{x}_t}{\\Delta t} - \\hat{\\mathbf{F}}(\\mathbf{x}_t) \\right) \\rangle.\n","$$\n","\n","where $\\Delta \\mathbf{x}_t = \\mathbf{x}_{t+\\Delta t} - \\mathbf{x}_t$ is the discrete velocity. Minimizing $\\mathcal{L}$ with respect to the coefficients $\\hat{F}_i$ gives the linear system:\n","\n","$$\n","\\mathbf{G} \\hat{\\mathbf{F}} = \\hat{\\mathbf{b}}.\n","$$\n","\n","where\n","\n","$$\n","G_{ij} = \\langle \\mathbf{b}_i(\\mathbf{x}_t)^T \\mathbf{D}^{-1} \\mathbf{b}_j(\\mathbf{x}_t) \\rangle, \\qquad\n","\\hat{b}_j = \\langle \\left( \\frac{\\Delta \\mathbf{x}_t}{\\Delta t} \\right)^T \\mathbf{D}^{-1} \\mathbf{b}_j(\\mathbf{x}_t) \\rangle,\n","$$\n","\n","If we expand the average over time the formulas read:\n","\n","$$\n","G_{ij} = \\frac{\\Delta t}{T} \\sum_{a=1}^d \\sum_{b=1}^d \\sum_t \\, b_{ia}(\\mathbf{x}_t) \\, (\\hat{D}^{-1})_{ab} \\, b_{jb}(\\mathbf{x}_t) = \\frac{\\Delta t}{T}  \\, b_{ia}(\\mathbf{x}_t) \\, (\\hat{D}^{-1})_{ab} \\, b_{jb}(\\mathbf{x}_t),\n",",\n","$$\n","\n","$$\n","\\hat{b}_i = \\frac{\\Delta t}{T} \\sum_{a=1}^d \\sum_{b=1}^d \\sum_t \\, \\frac{\\Delta x_{ta}}{\\Delta t} \\, (\\hat{D}^{-1})_{ab} \\, b_{ib}(\\mathbf{x}_t) = \\frac{\\Delta t}{T}  \\, \\frac{\\Delta x_{ta}}{\\Delta t} \\, (\\hat{D}^{-1})_{ab} \\, b_{ib}(\\mathbf{x}_t).\n","$$\n","\n","where for the second equality we have used the **Einstein summation** notation, for which repeated indices are summed over. Given two 2D numpy arrays A, and B of compatible dimensions `np.einsum('ik,kj->ij', A, B)` will implement the matrix product $(AB)_{ij} = \\sum_{k} A_{ik}B_{kj}$. You can use more than three matrices and implement more complicated summations: `np.einsum('ik,tk,tij->j', A, B, C)` will implement the product $A_{ik} B_{tk} C_{tij}$ where we use the repeated einstein summation convention. The function einsum has an option `optimize=True` which accelerates it.\n","\n","To help you, we provide a function called `get_basis` which returns a basis of functions of arbitrary polynomial degrees for arbitrary space dimensions. We also provide a function `evaluate_basis` which takes the functions basis, the data $X$ of dimension $(N_t, d)$ where the first axis is time, and the second is space, and evaluates $\\mathbf{b}(\\mathbf{x}_t)$ for all times and all basis. This returns a 3D array such that  $B_{tia} = b_{ia}(\\mathbf{x}_t)$.\n","\n","```python\n","# Returns a polynomial basis of degree 2 for variables of dimension d = 3\n","basis = get_basis(field_dim=3, degree=2)\n","\n","# Evalute the basis functions on the trajectory X of dimensions (Nt, d)\n","B = evaluate_basis(X, basis)\n","```\n","\n","**<font color='red'>Write the function `infer_force_coefficients` which computes $\\mathbf{G}$, $\\hat{\\mathbf{b}}$ and solves the linear system</font>**. Once the optimal coefficients $\\hat{F}_i$ have been inferred, the force field at any point $\\mathbf{x}$ will be reconstructed as a linear combination of the active basis functions. This is done with the function `reconstruct_force_field` which we provide. **<font color='red'>Compare the true and the inferred force field with a scatter plot.</font>**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BxsTJYC5z54_"},"outputs":[],"source":["def infer_force_coefficients(X, T, basis_functions):\n","    \"\"\"\n","    Estimate the force coefficients using Einstein summation instead of loops.\n","\n","    Parameters:\n","        X : ndarray of shape (Nt, d)\n","            Trajectory data.\n","        T : float\n","            Total simulation time.\n","        basis_functions : list of callables\n","            Basis functions mapping from position to vector field.\n","\n","    Returns:\n","        Fhat : ndarray of shape (nB,)\n","            Estimated force coefficients.\n","    \"\"\"\n","    dt = T/X.shape[0]\n","    dXdt = (X[1:] - X[:-1]) / dt\n","    B = evaluate_basis(X[:-1], basis_functions)\n","\n","    # TODO\n","\n","    return Fhat\n","\n","def reconstruct_force_field(X, coeffs, basis_functions):\n","    \"\"\"\n","    Reconstruct the inferred force field at each point in the trajectory.\n","\n","    Parameters:\n","        X : ndarray of shape (Nt, d)\n","            Trajectory positions.\n","        coeffs : ndarray of shape (nB,)\n","            Coefficients for the basis functions.\n","        basis_functions : dict of callables\n","            Dictionary of basis functions mapping to vector fields.\n","\n","    Returns:\n","        F : ndarray of shape (Nt, d)\n","            Reconstructed force field at each time step.\n","    \"\"\"\n","    Y = np.moveaxis(X, 0, 1)\n","    F = np.zeros_like(Y)\n","    for c, f in zip(coeffs, basis_functions.values()):\n","        F += c * f(Y)\n","    F = np.moveaxis(F, 1, 0)\n","    return F"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uMQKWe_zz54_"},"outputs":[],"source":["basis = get_basis(field_dim=3, degree=2)\n","coeffs = infer_force_coefficients(X, T, basis)\n","\n","# TODO"]},{"cell_type":"markdown","metadata":{"id":"oeZbo2h6z55A"},"source":["## 4. Maximizing the log-likelihood"]},{"cell_type":"markdown","metadata":{"id":"vliPDZk-z55A"},"source":["We denote $B$ the basis of functions used to infer the force, also denoted $\\hat{\\mathbf{F}}^B(\\mathbf{x})$. We can evaluate the **log-likelihood** of the trajectory under this force model:\n","\n","$$\n","\\mathcal{L}(\\hat{\\mathbf{F}}) = -\\frac{T}{4} \\langle  \\left( \\frac{\\Delta \\mathbf{x}_t}{\\Delta t} - \\hat{\\mathbf{F}}(\\mathbf{x}_t) \\right)^T \\hat{\\mathbf{D}}^{-1} \\left( \\frac{\\Delta \\mathbf{x}_t}{\\Delta t} - \\hat{\\mathbf{F}}(\\mathbf{x}_t) \\right) \\rangle.\n","$$\n","\n","One we have fit the force given the basis $B$, it is tempting to use a second time the value of the log-likelihood of the $\\mathcal{L}$ data to find the best basis $B$. However, this will favor models with more functions, which will overfit the data and lead to larger error on the force reconstruction.\n","\n","This can be seen using the equation for $\\mathcal{L}$ and $\\Delta \\mathbf{x}_t/\\Delta t = \\mathbf{F}(\\mathbf{x}_t) + \\sqrt{2\\mathbf{D}} \\boldsymbol\\eta_t/\\sqrt{\\Delta t}$. We get, if we also assume that the estimated diffusion matches well the true diffusion, ie $\\mathbf{D} \\simeq \\hat{\\mathbf{D}}$\n","\n","\\begin{align}\n","\\mathcal{L}(\\hat{\\mathbf{F}}^B) \\simeq - \\frac{T}{4} \\langle (\\mathbf{F} - \\hat{\\mathbf{F}}^B)) \\mathbf{D}^{-1} (\\mathbf{F} - \\hat{\\mathbf{F}}^B)) \\rangle + n_B - \\frac{d}{2 \\Delta t} \\\\\n","=- T \\mathcal{E}(\\mathbf{F}^{B}) + n_B - \\frac{d T}{2 \\Delta t}\n","\\end{align}\n","\n","where $n_B$ is the number of functions in the basis $B$, $d$ the dimension (here 3), and we recognize $\\mathcal{E}(\\mathbf{F}^{B})$ the reconstruction error between the **true** force field and the **inferred** one.Ze understand that by searching for a base that maximizes the log-likelihood (ie maximizing $\\mathcal{L}$, we will find a base $B^*$ that in fact solves:\n","\n","$$\n","B^* = \\arg\\max_{B} \\left( -T \\mathcal{E}(\\mathbf{F}^{B}) + n_B\\right)\n","$$\n","\n","Therefore, adding more function in the basis will be favored thanks to the term $n_B$, which can grow arbitrarily big. **This is overfitting**. We provide the `add_superfluous_functions` which will start from the true model and add functions which are not in the true model and returns the log-likelihood and the error for each of these new basis. **<font color='red'>Show that adding functions to the true model increases the log-likelihood, but also increases the error: this comes from the term proportional to $n_B$ in the equation above.</font>**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"swqKIR1Wz55A"},"outputs":[],"source":["def compute_log_likelihood(X, T, coeffs, basis_functions):\n","    \"\"\"\n","    Compute the log-likelihood of the trajectory under the inferred force.\n","\n","    Parameters:\n","        X : ndarray of shape (Nt, d)\n","            Trajectory data.\n","        T : float\n","            Total simulation time.\n","        coeffs : ndarray of shape (nB,)\n","            Coefficients for the basis functions.\n","        basis_functions : dict\n","            Dictionary of basis functions.\n","\n","    Returns:\n","        L : float\n","            Log-likelihood of the trajectory.\n","    \"\"\"\n","    dt = T/X.shape[0]\n","\n","    # TODO\n","\n","    return L\n","\n","def compute_reconstruction_error(X, T, coeffs, basis):\n","    \"\"\"\n","    Compute the error between the true and inferred force fields.\n","\n","    Parameters:\n","        X : ndarray of shape (Nt, d)\n","            Trajectory positions.\n","        T : float\n","            Total simulation time.\n","        coeffs : ndarray of shape (nB,)\n","            Coefficients for the inferred force.\n","        basis : dict\n","            Dictionary of basis functions.\n","\n","    Returns:\n","        error : float\n","            Scalar reconstruction error.\n","    \"\"\"\n","    dt = T/X.shape[0]\n","\n","    # TODO\n","\n","    return error\n","\n","\n","def add_superfluous_functions(X, T, basis, true_model):\n","    \"\"\"\n","    Add basis functions to the true model one by one, and track score changes.\n","\n","    Parameters:\n","        X : ndarray of shape (Nt, d)\n","            Trajectory data.\n","        T : float\n","            Total simulation time.\n","        basis : dict\n","            Dictionary of all available basis functions.\n","        true_model : dict\n","            Dictionary of ground-truth basis functions.\n","\n","    Returns:\n","        log_liks : ndarray\n","            Log-likelihood after each added function.\n","        errors : ndarray\n","            Reconstruction after each added function.\n","    \"\"\"\n","    dt = T/X.shape[0]\n","    all_labels = list(basis.keys())\n","    true_labels = list(true_model.keys())\n","\n","    remaining_labels = list(set(all_labels) - set(true_labels))\n","    np.random.shuffle(remaining_labels)\n","\n","    log_liks = []\n","    errors = []\n","    size_basis = []\n","\n","    current_labels = true_labels\n","\n","    for _label in remaining_labels:\n","        current_labels = current_labels + [_label]\n","        current_model = {label: basis[label] for label in current_labels}\n","\n","        coeffs = infer_force_coefficients(X, T, current_model)\n","        log_lik = compute_log_likelihood(X, T, coeffs, current_model)\n","        error = compute_reconstruction_error(X, T, coeffs, current_model)\n","\n","        log_liks.append(log_lik)\n","        errors.append(error)\n","        size_basis.append(len(current_model))\n","\n","    log_liks = np.array(log_liks)\n","    errors = np.array(errors)\n","    return log_liks, errors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PyPdx1HDz55B"},"outputs":[],"source":["true_labels = [\n","    \"$e_{0} u_{1}^{1}$\",\n","    \"$e_{0} u_{0}^{1}$\",\n","    \"$e_{1} u_{0}^{1}$\",\n","    \"$e_{1} u_{0}^{1} u_{2}^{1}$\",\n","    \"$e_{1} u_{1}^{1}$\",\n","    \"$e_{2} u_{2}^{1}$\",\n","    \"$e_{2} u_{0}^{1} u_{1}^{1}$\",\n","]\n","true_model = get_model_from_labels(true_labels, field_dim=3)\n","log_liks, errors = add_superfluous_functions(X, T, basis, true_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VM-JdxhYz55C"},"outputs":[],"source":["plt.figure()\n","plt.plot(log_liks, errors, 'o-')\n","plt.ylabel('reconstruction error')\n","plt.xlabel('log-likelihood, $\\mathcal{L}$')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"eyV_13V5z55C"},"source":["## 5. How to avoid overfitting ?"]},{"cell_type":"markdown","metadata":{"id":"HQGaqzmUz55C"},"source":["To avoid overfitting and select the best subset of basis functions, we would rather want to minimize directly the reconstruction error. Thanks to the relationship between the log-likelihood and the error, we see that if define a new penalized log-likelihood:\n","\n","$$\n","\\mathcal{L}_{\\mathrm{AIC}} (\\hat{\\mathbf{F}}^B) = \\mathcal{L} (\\hat{\\mathbf{F}}^B) - n_B\n","$$\n","\n","we are ensured that:\n","\n","$$\n","\\mathcal{L}_{\\mathrm{AIC}} \\simeq -T \\mathcal{E}(\\mathbf{F}^{B})\n","$$\n","\n","This is what we need, since now searching for a base which maximizes $\\mathcal{L}^{\\mathrm{AIC}}$ is the same as minimizing the reconstruction error. This is called the Aikaike Information Criterion.\n","\n","**However, we have hidden something, the relationship between the log-likelihood and the error only holds on average** over an ensemble of trajectories. For a single trajectory, this relation always has a non-zero probability not to hold, even for infinitely long ($T \\rightarrow \\infty$) and infinitely well sampled ($\\Delta t \\rightarrow 0$) trajectories. This means that we could include an incorrect function which increases $\\mathcal{L}^{\\mathrm{AIC}}$ while also increasing $\\mathcal{E}(\\mathbf{F}^{B})$: if this relation always held it should be impossible! For this reason, the authors of SFI recently proposed a modified criterion, called PASTIS, for which this phenomenon doesn't occur. This criterion reads:\n","\n","$$\n","\\mathcal{L}_{\\text{PASTIS}} = \\mathcal{L} (\\hat{\\mathbf{F}}^B) - n_B \\log\\left(\\frac{n_0}{p}\\right),\n","$$\n","\n","where $p$ is a parameter which sets the probability of having $\\Delta \\mathcal{L}_{\\mathrm{PASTIS}}$ and $\\Delta \\mathcal{E}$ having the same sign, and $n_0$ is the total number of functions in the basis.\n","\n","Using the function to `add_superfluous_functions`, you can compute the change in $\\Delta \\mathcal{L}_{\\mathrm{AIC}}$, $\\Delta \\mathcal{L}_{\\mathrm{PASTIS}}$ and $-T \\Delta \\mathcal{E}$ occuring everytime you add an additional function to the model. We provide a snippet of code to compute the log-likelihood and the error when adding superfluous functions for `ntrials=5`repetitions. **<font color='red'>From this, plot histograms of $\\Delta \\mathcal{L}_{\\mathrm{AIC}}$, $-T\\Delta \\mathcal{E}$ and $\\Delta \\mathcal{L}_{\\mathrm{PASTIS}}$.</font>**\n","\n","You should notice that $-T\\Delta \\mathcal{E}$ is always negative since adding a function that is not in the true model can only increase the reconstruction error. The interesting observation is then that $\\Delta \\mathcal{L}_{\\mathrm{AIC}}$ can be positive, even though on average it is negative. This means that adding an additional superfluous function is unfavored on average, but can be favored if we are unlucky. The other observation is that the effect of $\\Delta \\mathcal{L}_{\\mathrm{PASTIS}}$ is to shift the histogram towards more negative values, such that the probability of $\\Delta \\mathcal{L}_{\\mathrm{PASTIS}}$ being positive is negligible, and maximizing $\\Delta \\mathcal{L}_{\\mathrm{PASTIS}}$ is a better approach.\n","\n","Finally, we can go even beyond and predict that $\\Delta \\mathcal{L}$ is distributed like $Z/2$ where $Z \\sim \\chi_1^2$ is a chi-square variable. **<font color='red'>Plot this prediction on top of the histograms (there is a shift to account for to overlay it with $\\Delta \\mathcal{L}_{\\mathrm{AIC}}$ and $\\Delta \\mathcal{L}_{\\mathrm{PASTIS}}$).</font>**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7uh_BFoz55C"},"outputs":[],"source":["log_liks = []\n","errors = []\n","ntrials = 5\n","dt=0.0001\n","T=100.0\n","D=10\n","num=20\n","np.random.seed(2)\n","x0 = np.array([0.5, 0.5, 23])\n","force_args = (10.0, 28.0, 7.0/3.0)\n","\n","for _ in range(ntrials):\n","    X = simulate(x0, force_args, dt=dt, T=T, D=D, num = num)\n","    _log_liks, _errors = add_superfluous_functions(X, T, basis, true_model)\n","    log_liks.append(_log_liks)\n","    errors.append(_errors)\n","\n","log_liks = np.array(log_liks)\n","errors = np.array(errors)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F9wqztITz55C"},"outputs":[],"source":["# TODO"]},{"cell_type":"markdown","metadata":{"id":"Bik4xYJQz55D"},"source":["## 6. Final inference of the model"]},{"cell_type":"markdown","metadata":{"id":"wPj4NfRcz55D"},"source":["Finally, we provide a simple random search (greedy) function, called `greedy_basis_search`, to select a subset of basis functions that maximizes either the criterion PASTIS or AIC. It runs independent trials starting from random initial basis. At each step:\n","    \n","1. A singlefunction is either added or removed.\n","2. The model score is evaluated.\n","3. The move is accepted if the score improves.\n","4. The final basis is reached when the score doesn't improve anymore\n","\n","Among all trials, we keep the basis which maximixes the score. The result is a sparse, interpretable model with maximal predictive information. We provide a function `get_latex_model` which takes the functions basis dictionnary and returns a model formatted with latex. This can then be printed in the notebook using the Math routine of the IPython.display package. We also provide a method `get_model_from_labels` which constructs the functions basis for the Lorenz model, to allow for comparison. This will allow you to directly compare the final basis and see if you have inferred the right one. We provide the function `compute_scores` which returns the PASTIS and the AIC criterions. **<font color='red'>Play with the different criterion, change the values of $T$, of `num`and see which criterion performs the best.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q2P6PDsoz55D"},"outputs":[],"source":["def compute_scores(X, T, coeffs, basis_functions, n0, p=0.001):\n","    \"\"\"\n","    Compute model selection scores (PASTIS and AIC) for a given inferred model.\n","\n","    Parameters:\n","        X : ndarray of shape (Nt, d)\n","            Trajectory data.\n","        T : float\n","            Total simulation time.\n","        coeffs : ndarray of shape (nB,)\n","            Inferred force coefficients.\n","        basis_functions : dict\n","            Dictionary of active basis functions.\n","        n0 : int\n","            Total number of basis functions in the full pool.\n","        p : float\n","            Prior inclusion probability for PASTIS.\n","\n","    Returns:\n","        PASTIS : float\n","        AIC : float\n","    \"\"\"\n","    L = compute_log_likelihood(X, T, coeffs, basis_functions)\n","    nB = len(coeffs)\n","\n","    PASTIS = L - nB * np.log(n0 / p)\n","    AIC = L - nB\n","    return (PASTIS, AIC)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvZK9UA0z55D"},"outputs":[],"source":["dt=0.0001\n","T=100.0\n","D=10\n","num=20\n","np.random.seed(2)\n","x0 = np.array([0.5, 0.5, 23])\n","force_args = (10.0, 28.0, 7.0/3.0)\n","\n","simulate(x0, force_args, dt=dt, T=T, D=D, num = num)\n","sfi_engine = (infer_force_coefficients, compute_scores, compute_mean_diffusion)\n","fbasis, fcoeffs, _ = greedy_basis_search(X, T, basis, sfi_engine, p = 0.001, method = 'PASTIS')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EjsGxYHSz55D"},"outputs":[],"source":["from IPython.display import Math\n","Math(get_latex_model(fbasis, fcoeffs, scale_factors=None))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x1EwCiwfz55D"},"outputs":[],"source":["print(set(fbasis.keys()) == set(true_model.keys()))"]}],"metadata":{"kernelspec":{"display_name":"scrna","language":"python","name":"scrna"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}